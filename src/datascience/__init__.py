import os
import sys
import logging

logging_str="[%(asctime)s: %(levelname)s: %(module)s: %(message)s]"
#

log_dir="logs"
log_filepath=os.path.join(log_dir,"logging.log")
os.makedirs(log_dir,exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format=logging_str,
    #it will print the logging in the file
   

    handlers=[
        logging.FileHandler(log_filepath),
        logging.StreamHandler(sys.stdout)
        #it will print the logging in the console

    ]
)

logger=logging.getLogger("datasciencelogger")
"""Perfect question üëå You don‚Äôt just want to know *what* the code is doing, but also *why*, *when*, and *what happens if you don‚Äôt use it*. Let‚Äôs break it down in plain terms.

---

## üîπ What is Logging?

Logging is a way for your program to **record events while running**. Think of it like a diary of what happened:

* When did something happen?
* Was it successful, a warning, or an error?
* Which part of the code was responsible?

---

## üîπ Why use logging (instead of just `print`)?

‚úÖ **Advantages of logging**

* **More informative** ‚Üí Each log has a timestamp, severity level, and module name.
* **Separation of outputs** ‚Üí Errors, warnings, and info can be filtered.
* **Persistent** ‚Üí Logs are saved to a file (`logging.log`), so you can review them later. `print()` messages are gone once the program ends.
* **Scalable** ‚Üí In large projects, logging helps you debug without scattering `print()` everywhere.
* **Professional practice** ‚Üí Production systems (web apps, data pipelines, ML models) always rely on logs.

üö´ **If you don‚Äôt use logging**

* You‚Äôll rely only on `print()` ‚Üí no timestamps, no levels, no persistent record.
* Debugging large projects becomes painful.
* In production, you lose visibility of what went wrong after the program finishes.

---

## üîπ How does your code help?

* By using **two handlers**:

  1. `FileHandler` ‚Üí Saves logs into a file (`logs/logging.log`) for long-term analysis.
  2. `StreamHandler` ‚Üí Shows logs in the console immediately, so you can watch things in real time.

That‚Äôs why you‚Äôre doing:

```python
handlers=[
    logging.FileHandler(log_filepath),
    logging.StreamHandler(sys.stdout)
]
```

Without one of them:

* **No FileHandler** ‚Üí You can see logs only in the console, but nothing is saved.
* **No StreamHandler** ‚Üí You won‚Äôt see real-time logs in the console; you‚Äôll have to open the log file to check.

---

## üîπ When to use logging?

* **During development**: To debug your code with INFO/DEBUG logs.
* **In production**: To monitor errors, performance issues, or unexpected behavior.
* **In long-running jobs**: (e.g., machine learning training, ETL pipelines) ‚Üí logs track progress and failures without babysitting the terminal.
* **In team projects**: Everyone can look at the same log file instead of relying on personal `print()` messages.

---

## üîπ Example (with vs without logging)

### Without logging (only `print`):

```python
print("Data loaded")
print("Model training started")
print("Error: learning rate too high")
```

‚ùå Problems:

* No timestamp ‚Üí when did it happen?
* No severity ‚Üí is this just info or a real error?
* No persistence ‚Üí output is lost when program ends.

---

### With logging:

```python
logger.info("Data loaded")
logger.info("Model training started")
logger.error("Learning rate too high")
```

Output in console (and also saved in `logging.log`):

```
[2025-09-12 15:30:01,456: INFO: my_module: Data loaded]
[2025-09-12 15:30:02,123: INFO: my_module: Model training started]
[2025-09-12 15:30:02,789: ERROR: my_module: Learning rate too high]
```

‚úÖ Now you know **when, what, where, and how severe** the message is.

---

üëâ So to summarize:

* **How**: You set up logging with format + handlers (file + console).
* **Why**: For debugging, monitoring, and professional development.
* **When**: In both development (to debug) and production (to monitor).
* **What if not there**: You lose timestamps, severity levels, persistence, and debugging becomes much harder.

---

Do you want me to also explain the **different logging levels** (`DEBUG`, `INFO`, `WARNING`, `ERROR`, `CRITICAL`) with examples? That usually makes it crystal clear when to use which.
Got it üëç Let me break this down step by step so you understand **exactly what your code is doing** and why.

---

### 1. Importing modules

```python
import os
import sys
import logging
```

* **os** ‚Üí lets you work with the file system (paths, directories).
* **sys** ‚Üí gives access to system-related objects (like `stdout` = standard output, i.e. the console).
* **logging** ‚Üí Python‚Äôs built-in module for logging messages (info, warning, error, etc.).

---

### 2. Defining log message format

```python
logging_str = "[%(asctime)s: %(levelname)s: %(module)s: %(message)s]"
```

* This defines how each log entry will look.
* `%(asctime)s` ‚Üí timestamp (when the log happened).
* `%(levelname)s` ‚Üí log level (INFO, ERROR, etc.).
* `%(module)s` ‚Üí the module (file) where the log was created.
* `%(message)s` ‚Üí the actual log message.

So a log might look like:

```
[2025-09-12 10:30:45,123: INFO: my_module: Data loaded successfully]
```

---

### 3. Setting up log file directory

```python
log_dir = "logs"
log_filepath = os.path.join(log_dir, "logging.log")
os.makedirs(log_dir, exist_ok=True)
```

* `log_dir = "logs"` ‚Üí all logs will go into a folder called `logs`.
* `log_filepath` ‚Üí `"logs/logging.log"`.
* `os.makedirs(..., exist_ok=True)` ‚Üí creates the folder if it doesn‚Äôt already exist (so no errors happen if you run the script multiple times).

---

### 4. Configuring logging

```python
logging.basicConfig(
    level=logging.INFO,
    format=logging_str,
    handlers=[
        logging.FileHandler(log_filepath),
        logging.StreamHandler(sys.stdout)
    ]
)
```

This is the **heart of the setup**:

* `level=logging.INFO` ‚Üí minimum level of logs to capture. (INFO, WARNING, ERROR will show; DEBUG won‚Äôt unless you lower it).
* `format=logging_str` ‚Üí use the format we defined earlier.
* `handlers=[...]` ‚Üí where logs should go:

  * `logging.FileHandler(log_filepath)` ‚Üí write logs into `logs/logging.log` file.
  * `logging.StreamHandler(sys.stdout)` ‚Üí also print logs live to the terminal (console output).

üëâ This is why you see the same log in **both the console and the log file**.

---

### 5. Creating a logger object

```python
logger = logging.getLogger("datasciencelogger")
```

* This creates a named logger called `"datasciencelogger"`.
* Instead of calling `logging.info()`, you‚Äôll now use `logger.info()`, `logger.error()`, etc.
* This is useful when you have **multiple loggers** in different modules (helps organize logs).

---

‚úÖ **In short:**

* You are creating a logging system that writes logs **both to a file and the console**.
* The format is structured for readability and debugging.
* A named logger (`datasciencelogger`) is created for consistency across your project.

---

üëâ Do you want me to also show you an **example run** (where I log some messages and show how they appear in console and file)?
"""